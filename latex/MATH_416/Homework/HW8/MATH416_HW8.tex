\documentclass{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{array}
\usepackage[font=small, labelfont={sf,bf}, margin=1cm]{caption}
\usepackage{tabularx}
\usepackage{amssymb}



\date{Due: Oct 30 Edit: \today}
\title{MATH 416H HW 8}
\author{James Liu}

\begin{document}
\maketitle
\begin{itemize}
    \item [1.] 
    \begin{itemize}
        \item [a)]    \begin{align*}\det\left(
            \begin{bmatrix}
                1&2&0\\
                1&1&5\\
                1&-3&0
            \end{bmatrix}\right)&=
            -5\times \left|\begin{matrix}
                1&2\\
                1&-3
            \end{matrix}\right|\\
            &=25
        \end{align*}
        \item [b)] 
        \begin{align*}\det\left(
            \begin{bmatrix}
                4&-6&-4&4\\
                2&1&0&0\\
                0&-3&1&3\\
                -2&2&-3&-5
            \end{bmatrix}\right)&=2\times\left|\begin{matrix}
                2&-3&-2&2\\
                2&1&0&0\\
                0&-3&1&3\\
                -2&2&-3&-5
            \end{matrix}\right|
            \\
            &=2\times\left|\begin{matrix}
                2&-3&-2&2\\
                0&4&2&-2\\
                0&-3&1&3\\
                0&-1&-5&-3
            \end{matrix}\right|\\
            &=-2\times\left|\begin{matrix}
                2&-3&-2&2\\
                0&-1&-5&-3\\
                0&-3&1&3\\
                0&4&2&-2\\
            \end{matrix}\right|\\
            &=-2\times\left|\begin{matrix}
                2&-3&-2&2\\
                0&-1&-5&-3\\
                0&0&16&12\\
                0&0&-18&-14\\
            \end{matrix}\right|\\
            &=-2\times4\times2\times\left|\begin{matrix}
                2&-3&-2&2\\
                0&-1&-5&-3\\
                0&0&4&3\\
                0&0&-9&-7\\
            \end{matrix}\right|\\
            &=-16\times2\times(-1)\left|\begin{matrix}
                4&3\\-9&-7
            \end{matrix}\right|\\
            &=32\times (-28-(-27))\\
            &=-32
        \end{align*}
    \end{itemize}

    \item [2.]
    \begin{align*}
        \det\left(
            \begin{bmatrix}
                1&x&x^2\\
                1&y&y^2\\
                1&z&z^2
            \end{bmatrix}\right)&=\left|\begin{matrix}
                1&x&x^2\\
                0&(y-x)&(y^2-x^2)\\
                0&(z-x)&(z^2-x^2)
            \end{matrix}\right|\\
            &=1\times ((y-x)(z-x)(z+x)-(z-x)(y-x)(y+x))\\
            &=(y-x)(z-x)(z+x-(y+x))\\
            &=(y-x)(z-x)(z-y)
    \end{align*}
    \item [3.]\
    \begin{itemize}
        \item [forward:] If column of \(B\) forms a basis in \(F^n\), then all the column vectors are linearly independent with each other. Thus, noteing the columns in matrix \(A\) as \(v_1,\cdots,v_n\).
        Then, for some \(x_i\in F\), \(x_1v_1+\cdots+x_nv_n=0\) means \(x_1=\cdots=x_n=0\). Thus, \(Ax=0\) give only solution of \(x = \overrightarrow{0}\). Therefore \(N(T)=\{\overrightarrow{0}\}\). Thus the map is 
        invertable. Thus \(\det(A)\neq 0\)

        \item [backward:] If \(\det(A)\neq 0\),then the function is invertable meaning that \(N(T)=\{\overrightarrow{0}\}\). Thus, the only solution for \(Ax=0\) is \(x=\overrightarrow{0}\),
                or the only solution for \(x_1v_1+\cdots x_nv_n=0\) is \(x_1=\cdots=x_n=0\). Therefore, the column vectors are linearly independent to each other. As there are in total \(n\) linearly independent vectors in \(F\), it forms a basis in \(F^n\)
    \end{itemize}
    \item [4.]
    As \(\dim(V)=1\), then we can write out a basis for \(V\), \(\{b\}\), \(\forall v\in V\), \(v=\lambda b\) for some \(\lambda\in F\). Thus:
    Supposse that \(T(b)=v\), \(v = \lambda b\). For any other vector \(w\in V\), \(w = \mu b\), then \(T(w)=T(\mu b)=\mu T(b)= \mu \lambda b = \lambda (\mu b)=\lambda w\). Thus, there exsist a unique \(\lambda\) for such map.
    \item [5.]
    \begin{itemize}
        \item [a)] 
        \[\det(N^k)=0=\left(\det(N)\right)^k=\det(N)\]
        \item [b)]\[
        \begin{bmatrix}
            0&1&2\\
            0&3&4\\
            0&5&6
        \end{bmatrix}\]
    \end{itemize}
    \item [6.]
        \begin{align*}
            \det(A)&=\det(A^T)\\
            \det(AA^T)=\det(A)\det(A^T)&=\det(I)=1\\
            \det(A)^2&=1\\
            \det(A)=\det(A^T)&=\pm 1 
        \end{align*}
    \item [7.]
    \begin{itemize}
        \item [a)]
        \begin{align*}
            b(v_1+v_2,w)&=\ell_1(v_1+v_2)\ell_2(w)\\
            &=\ell_1(v_1)\ell_2(w)+\ell_1(v_2)\ell_2(w)\\
            &=b(v_1,w)+b(v_2,w)\\
            b(\lambda v,w)&=\ell_1(\lambda v)\ell_2(w)\\
            &=\lambda \ell_1(v)\ell_2(w)\\
            &=\lambda(b(v,w))
        \end{align*}
        Similar the two properties can be profed for \(\ell_2\) and thus it is bilinear.
        \item [b)]
        \begin{align*}
        (\ell_1 \wedge  \ell_2)(v,w)&=b(v,w)-b(w,v)\\
        (\ell_1 \wedge  \ell_2)(v_1+v_2,w)&=b(v_1+v_2,w)-b(w,v_1+v_2)\\
        &=b(v_1,w)+b(v_2,w)+b(w,v_1)+b(w,v_2)\\
        &=(b(v_1,w)+b(w,v_1))+(b(v_2,w)+b(w,v_2))\\
        &=(\ell_1\wedge \ell_2)(v_1,w)+(\ell_1\wedge \ell_2)(v_2,w)\\
        (\ell_1\wedge \ell_2)(\lambda v,w)&=b(\lambda v,w)-b(w,\lambda v)\\
        &=\lambda b( v,w)-\lambda b(w, v)\\
        &=\lambda (b(v,w)-b(w,v))\\
        &=\lambda (\ell_1\wedge \ell_2)(v,w)
        \end{align*}
        Similar the two properties can be profed for \(w\), and thus it is bilinear.\\
        \begin{align*}
            (\ell_1 \wedge  \ell_2)(v,w)&=b(v,w)-b(w,v)\\
            (\ell_1 \wedge  \ell_2)(w,v)&=b(w,v)-b(v,w)\\
            &=-(b(v,w)-b(w,v))\\
            &=-(\ell_1 \wedge  \ell_2)(v,w)
        \end{align*}
        Thus, it is alternating.
    \end{itemize}
    \item [8.]
    \begin{itemize}
        \item [a)] \(\alpha,\beta \in \text{Alt}^k(V)\), Define vector addition and scaler multiplication as following:
        \begin{align*}
            (\alpha+\beta)(v_1,\cdots,v_k)&=\alpha(v_1,\cdots,v_k)+\beta(v_1,\cdots,v_k)\\
            (\lambda \alpha)(v_1,\cdots,v_k)&=\lambda \alpha(v_1,\cdots,v_k)
        \end{align*}
        And zero vector as \(T\in \text{Alt}^k(V), T(x)=0\).
        \begin{align*}
            (\alpha+\beta)(v_1+v_1',\cdots,v_k)&=\alpha(v_1+v_1',\cdots,v_k)+\beta(v_1+v_1',\cdots,v_k)\\
            &=\alpha(v_1,\cdots,v_k)+\beta(v_1,\cdots,v_k)+\alpha(v_1',\cdots,v_k)+\beta(v_1',\cdots,v_k)\\
            &=(\alpha+\beta)(v_1,\cdots,v_k)+(\alpha+\beta)(v_1',\cdots,v_k)\\
            (\alpha+\beta)(\lambda v_1,\cdots,v_k)&=\alpha(\lambda v_1,\cdots,v_k)+\beta(\lambda v_1,\cdots,v_k)\\
            &=\lambda (\alpha+\beta)(v_1,\cdots,v_k)\\
            (\alpha+\beta)(v_2,\cdots,v_k,v_1)&=-\alpha(v_1,\cdots,v_k)-\beta(v_1,\cdots,v_k)\\
            &=-(\alpha+\beta)(v_1,\cdots,v_k)\\
            (\lambda \alpha)(v_1+v_1',\cdots,v_k)&=\lambda \alpha(v_1+v_1',\cdots,v_k)\\
            &=(\lambda \alpha)(v_1,\cdots,v_k)+(\lambda \alpha)(v_1',\cdots,v_k)\\
            (\lambda \alpha)(\mu v_1,\cdots,v_k)&=\lambda \alpha(\mu v_1,\cdots,v_k)\\
            &=\mu \lambda \alpha(v_1,\cdots,v_k) \\
            &=\mu (\lambda \alpha)(v_1,\cdots,v_k)\\
            (\lambda \alpha)(v_2,\cdots,v_k,v_1)&=-\lambda \alpha(v_1,\cdots,v_k)\\
            &=-(\lambda \alpha)(v_1,\cdots,v_k)\\
            (\alpha +T)(v_1,\cdots,v_k)&=\alpha(v_1,\cdots,v_k)+T(v_1,\cdots,v_k)\\
            &=\alpha(v_1,\cdots,v_k)
        \end{align*}
        And the other 8 properties also holds, Thus, it is a vector space.
        \item [b)]Choose a basis for \(V\), \(\{b_1,b_2\}\) and \(\{b_1^*,b_2^*\}\) be a basis for the dual basis. Then
        \(\forall v_1,v_2\in V, (b^*_1\wedge b^*_2)(v_1,v_2)=b_1^*(v_1)b_2^*(v_2)-b_1^*(v_2)b_2^*(v_1)\). Take \(v_1=b_1,v_2=b_2\), \((b^*_1\wedge b^*_2)(b_1,b_2)=1\times 1 - 0\times 0 =1\neq 0\) Thus the wedge is not zero map.
        \(\forall v_1,v_2\in V,\alpha \in \text{Alt}^2(V)\)
        \begin{align*}
            \alpha(v_1,v_2)&=\alpha(\lambda_1b_1+\lambda_2b_2,\mu_1b_1+\mu_2b_2)\\
            &=\alpha(\lambda_1b_1,\mu_1b_1+\mu_2b_2)+\alpha(\lambda_2b_2,\mu_1b_1+\mu_2b_2)\\
            &=\alpha(\lambda_1b_1,\mu_1b_1)+\alpha(\lambda_1b_1,\mu_2b_2)+\alpha(\lambda_2b_2,\mu_1b_1)+\alpha(\lambda_2b_2,\mu_2b_2)\\
            &=\lambda_1\mu_1\alpha(b_1,b_1)+\lambda_1\mu_2\alpha(b_1,b_2)+\lambda_2\mu_1\alpha(b_2,b_1)+\lambda_2\mu_2\alpha(b_2,b_2)\\
            &=(\lambda_1\mu_2-\lambda_2\mu_1)\alpha(b_1,b_2)\\
            (b^*_1\wedge b^*_2)(v_1,v_2)&=b^*_1(\lambda_1b_1+\lambda_2b_2)b_2^*(\mu_1b_1+\mu_2b_2)-b^*_2(\lambda_1b_1+\lambda_2b_2)b_1^*(\mu_1b_1+\mu_2b_2)\\
            &=\lambda_1\mu_2-\lambda_2\mu_1
        \end{align*}
        Thus \(\alpha(v_1)(v_2) = \alpha(b_1,b_2)((b^*_1\wedge b^*_2)(v_1,v_2)) \), therfore it spans and the dimension is 1.
        \newpage
        \item [c)] Using same notation with \(b)\).
        \begin{itemize}
            \item [span:]
            \begin{align*}
                \alpha(v_1,v_2)&=\alpha(\lambda_1b_1+\lambda_2b_2+\lambda_3b_3,\mu_1b_1+\mu_2b_2+\mu_3b_3)\\
                &=(\lambda_1\mu_2-\lambda_2\mu_1)\alpha(b_1,b_2)+(\lambda_1\mu_3-\lambda_3\mu_1)\alpha(b_1,b_3)+(\lambda_2\mu_3-\lambda_3\mu_2)\alpha(b_2,b_3)
                \\(b^*_1\wedge b^*_2)(v_1,v_2)&=\lambda_1\mu_2-\lambda_2\mu_1\\
                (b^*_1\wedge b^*_3)(v_1,v_2)&=\lambda_1\mu_3-\lambda_3\mu_1\\
                (b^*_2\wedge b^*_3)(v_1,v_2)&=\lambda_2\mu_3-\lambda_3\mu_2\\
                \alpha(v_1,v_2)&=\alpha(b_1,b_2)\cdot(b^*_1\wedge b^*_2)(v_1,v_2)+\alpha(b_1,b_3)\cdot(b^*_1\wedge b^*_3)(v_1,v_2)\\ 
                &+\alpha(b_2,b_3)\cdot(b^*_2\wedge b^*_3)(v_1,v_2)
            \end{align*}
            \item [linear independent:]\(\forall v_1,v_2 \in V\), if:
            \begin{align*}
                \chi_1(b^*_1\wedge b^*_2)(v_1,v_2)+ \chi_2(b^*_1\wedge b^*_3)(v_1,v_2)+\chi_3(b^*_2\wedge b^*_3)(v_1,v_2)&=0\\
            \end{align*}
            Take \(v_1=b_1+b_2,v_2=b_2+b_3\), then we have: 
            \begin{align*}
                (b^*_1\wedge b^*_2)(v_1,v_2)&=\lambda_1\mu_2-\lambda_2\mu_1=1\\
                (b^*_1\wedge b^*_3)(v_1,v_2)&=\lambda_1\mu_3-\lambda_3\mu_1=1\\
                (b^*_2\wedge b^*_3)(v_1,v_2)&=\lambda_2\mu_3-\lambda_3\mu_2=1\\
            \end{align*}
            Thus, for the equality to hold, \(\chi_1=\chi_2=\chi_3\) Thus they are linearly independent.
        \end{itemize}
        Thus, it is a set of basis.
    \end{itemize}

\end{itemize}
\end{document}